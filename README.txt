========
OVERVIEW
========

This was an interesting project, not too difficult, but it certainly offered opportunities for good
design (principles of encapsulation) and unit testing. While the assignment did not call for it
specifically, completeness demanded that I devote a lot of code (and unit tests) to validation.
Handling things like

 - missing fields in a csv line
 - improperly formatted dates
 - delivery records that refer to placements that don't exist
 - date ranges where the end date precedes the start date.

 Similarly, I tried to be as tolerant as possible, noticing that in the sample input files, there was
 some inconsistency with dates (some like 12/1/20 and others 12/15/2020). These little quirks added
 small demands on both the actual classes and the unit tests.

============================
PACKAGING AND OPERATIONS
============================
This program was written in Java 1.8 (my strongest language). You will need that language, as well as a tool called
maven that helps with managing the program's dependencies and with program building. You will probably find an IDE
like Intellij or eclipse useful for navigating the program's source files.

The source code is delivered in the form of a git bundle file. You can convert that file into a local instance
of the 'placements' git repository with this command.
    git clone placements.bundle
Then, cd into that 'placements' directory where you will be at the 'root' directory that contains all my source code.

Note, also, that you will see input files for the program
 - delivery.csv
 - placements.csv
 - dateQuery.txt

I used maven for both dependencies and a way to build the program. Run
  mvn package
to build the program. That command will also execute all the unit tests before creating an executable jar in the
'target' sub directory. Note that unit tests can also be run with 'mvn test'

The app can be run with and without date-range queries. To run the app with date-range queries, run
    java -jar target/placements-1.0-SNAPSHOT-launcher.jar -qf dateQuery.txt
And to run it without date queries, run
    java -jar target/placements-1.0-SNAPSHOT-launcher.jar

By default, the program will use the placements.csv and delivery.csv files. The default condition is to run the program
without a rangeQuery file. The user can control what files are used for all 3 purposes as is shown from the
following output generated by using the '-help' command line option

    Usage: |-df deliveryFileName| |-pf placementFileName| |-qf queryFileName| |-help|
      deliveryFileName:     default = delivery.csv
      placementFileName:    default = placements.csv
      queryFileName:        default = <null>

which was generated by running
    java -jar target/placements-1.0-SNAPSHOT-launcher.jar -help

============================
REQUIREMENTS QUESTIONS
============================

As I read through the program instructions, there were a few questions that came to mind.
- Where should program results be written? (stdout?, a file?, multiple files for different types of output?)
- Regarding the date-range queries, how would such queries be passed to the program? (read from stdin? read from a file?)

For each of these questions, I took a simple approach. For now, program results are written to stdout. Internally, the
two classes responsible for printing output (DateRangeReportPrinter and PlacementCountReportPrinter) take in their
respective constructors a Java 'PrintWriter' parameter that currently wraps stdout. If the 'PrintWriter' arguments
were to instead wrap another output medium, the two XXXReportPrinter classes would (without modification) write their
output to these other locations. In fact, for my "integration level" unit test, I pass PrintWriters that collect
String output which causes the XXXReportPrinter classes to write their output to a String, so all program output
can be captured and easily compared to expected values.

Regarding date-range queries, these queries currently come from an optional file argument, with one ranqe query expected
per line. Operationally, that seemed easier than having the user type the queries via a prompt on stdin.

============================
GENERAL DESIGN PRINCIPLES
============================

This program is comprised of many very small classes. It adheres to the 'SingleResponsibilty' SOLID principle where
each class does one thing well. I know that not every company likes this practice as they feel that it makes it harder
to see the big picture, but it does lead to more testable and maintainable code. Note, that I could have carried
this even further than I did, but chose a balanced approach.

Also, I made heavy use of Java 'streams'. Hopefully readers of this program are familiar with them. My understanding
is that Java streams are much like Ruby enumerators so hopefully they will be understood. For those used to them,
Java streams produce easy to understand programs, allowing the developer to stitch together small operations much
like Unix pipes can in the shell. Additionally, from a resource point of view, they are preferrable to passing around
and building collections since Streams allow classes to effectively pass around instances of qualifying classes
without first gathering them in an in-memory collection.

The program also makes use of a design principle called 'Dependency Injection'. With this approach, classes do not
directly instantiate the components they depend on. This approach leads to more flexible and testable code. I would
be very happy to expand on the benefits of this approach, in future conversations.

============================
DATA STRUCTURES/STORAGE
============================

The program seems to mimic a system where Placement and Delivery data is persisted in a database. Early in the
execution of this program, files with placement and delivery data are read and parsed, and passed to an object
of class 'DataStore' where they are 'persisted' and made available to the reporting/analysis functionalities
of the program. All storage and retrieval operations are encapsulated within class DataStore. In fact, it is
easy to see the program evolving to one that used a 'real' database. Were that to happen DataStore could be
rewritten to wrap database operations, but the rest of the program could remain unchanged.

The data structures in class DataStore are optimized for the ways that the program accesses these two data types.
For Placement data, the ability to perform quick searches with the placementId is important. This argued for a map
or array style lookup. Also, I noticed that the sample output report presented in the instructions is ordered
by the placementId, so a data structure that is ordered also seemed like a good idea. This led me to considering
an array keyed by placementId or a TreeMap (quick lookups and ordering by placementId). Obviously, nothing is quicker
than an array, but of course arrays in Java are not dynamic and we wouldn't know how many placementIds we'd have
to deal with. I subclassed Java's arrayList to create a general purpose class I called DynamicArray for this
purpose. Note that my use of this class was partially based on the observation that placementIds in the sample
file are small and contiguous. With my approach, gaps in placementIds are permissable, but we'd waste a lot of space
if we continued to use small placementIds like 1,2,3,4 and then suddenly had one like 1,233,979. If that is a
possibility, a switch to use TreeMap instead of DynamicArray would be necessary.

For Delivery records, the date-range query drove my selection of a data structure. To perform optimally, the
date-range query requires that we select delivery records that fall in the desired date range without having
to sift through every Delivery record to find those that qualify. A java TreeMap keyed by Date, with each date
indexing a list of Delivery records with that date, seemed ideal. TreeMap has easy and quick operations to
extract those records that fall within ranges and the DataStore takes advantage of those.

============================
PROGRAM FLOW
============================
The main() function for this program is in a class called 'Processor'. The main() function utilizes an instance
of class ArgParser to gather command line arguments (file names) and make them available. The argParser is passed to a
createProcessor() static method that instantiates and stitches together all the programs component classes,
providing each class with the dependencies it needs to do its job. By the time that an instancee of class Processor
is instantiated, the input files names have been transformed into corresponding file streams which can be easily
processed. Once the Processor has been created, its process() method is called, and all subsequent program activity
stems from calls originating in the process() method. In that method, one can easily see that the program lifetime
consists of 3 operations:

  - persisting the data from the two files
  - creating a placementCount report
  - creating a dateRange report.

Along the way these functionalities make use of small well encapsulated classes that perfom small relatively simple
operations. So, for example, the persistData() method makes use of a parser object to validate and transform lines of
text into either DeliveryRecords or  PlacementRecords depending on which file the text line originated from. Those
records are then passed to the DataStore where they are persisted.

============================
THOUGHTS ABOUT ERRORS
============================
No mention of errors was made in the program instructions. Additionally, the sample data files presented in the
instructions have no errors in them. Still, I felt it a good idea to write this program in a way representative
of how I'd write a production program where error detection and handling is crucially important.

As a result, classes like Parser and FieldMapper deal with improperly formatted lines of text in the input files.
Other errors (for example a DeliveryRecord which refers to a non-existent PlacementRecord) are discovered during
report generation.

Note that when errors are encountered, they are logged and processing continues by simply omitting or disregarding
the offending record/line.

Hopefully readers of this program will be tolerant of the way that such considerations led to more code that
must be read. These considerations probably doubled the amount of functional code, and more than doubled
the amount of Unit Test Code.

============================
UNIT AND INTEGRATION TESTS
============================
I believe that every significant functionality (classes and methods) within the program has thorough unit
tests devoted to them. The desire to write 'testable' code impacted the way that the solution was structured,
just as it does in real work.

Worthy of note, there is one special unit test, which in fact is really an integration test. The test in class
ProcessorTest, is effectively a complete run of the program with default inputs, and verifies that the
desired reports are produced.




